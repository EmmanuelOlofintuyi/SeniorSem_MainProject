{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0337498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb80626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a relatively small dataset for ease of testing which is located in the assets folder of this directory. \n",
    "#Data set is ~700 images of 10 species of monkeys in 10 subfolders labeled n0-n9.\n",
    "#Dataset can be found here: https://www.kaggle.com/datasets/slothkong/10-monkey-species?resource=download\n",
    "training_dataset_path = './assets/monkey_data/training/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1e3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset includes images from varying size so we build a transform tensor to resize them\n",
    "training_transforms = transforms.Compose([transforms.Resize((224,244)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbaa953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the dataset\n",
    "training_dataset = torchvision.datasets.ImageFolder(root = training_dataset_path, transform = training_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7de7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a loader with batch size 32\n",
    "training_loader = torch.utils.data.DataLoader(dataset = training_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd18b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanAndSTD(loader):\n",
    "    mean = 0. \n",
    "    std = 0.\n",
    "    #keeping track of images that have been processed to calculate final mean\n",
    "    images_counted = 0   \n",
    "    for batch, _ in loader:\n",
    "        #in case final batch size is < 32\n",
    "        current_batch_size = batch.size(0)   \n",
    "        \n",
    "        #reshaping image from the batch from [32, 3, 224, 224] to shape [32, 3, 50176] for calculation of Mean and STD\n",
    "        batch = batch.view(current_batch_size, batch.size(1), -1)   #the -1 value causes view() to calculate remaining size\n",
    "        \n",
    "        #updates mean, std, and total images processed for final mean, std calculation\n",
    "        mean += batch.mean(2).sum(0)\n",
    "        std += batch.std(2).sum(0)\n",
    "        images_counted = current_batch_size   \n",
    "    \n",
    "    #Updating final mean, std using the number of total images processed from loader\n",
    "    mean /= images_counted\n",
    "    std /= images_counted\n",
    "    \n",
    "    #returns two values, mean and std, as a tuple containing torch.Tensor objects eg: tuple =(torch.Tensor,torch.Tensor)\n",
    "    return mean, std        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a7a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper method to print mean and std for demonstration purposes\n",
    "def printMeanAndSTD(mean_and_std):\n",
    "    mean_text = str(mean_and_std[0])\n",
    "    std_text = str(mean_and_std[1])\n",
    "    msg = 'Mean of dataset: ' + mean_text +  '\\nSTD of dataset: ' + std_text\n",
    "    return msg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3cebe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getMeanAndSTD() returns two values as a tuple, as demonstrated below\n",
    "mean_and_std_tuple = getMeanAndSTD(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0928c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_and_std_tuple \t->>  <class 'tuple'>\n",
      "mean_and_std_tuple[0]\t->>  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print('mean_and_std_tuple \\t->> ',type(mean_and_std_tuple))\n",
    "print('mean_and_std_tuple[0]\\t->> ',type(mean_and_std_tuple[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d3657a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of dataset: tensor([53.1845, 52.7550, 40.1144])\n",
      "STD of dataset: tensor([25.9826, 25.3292, 24.8666])\n"
     ]
    }
   ],
   "source": [
    "#Finally, the mean and standard deviation for the dataset (mostly for demonstration and testing)\n",
    "print(printMeanAndSTD(mean_and_std_tuple))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
