# -*- coding: utf-8 -*-
"""Senior Seminar Model Training

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13e_HXEcrd_BCOktMFBXz3ekfgYmVRSx3
"""

!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html

import torch
import torch.nn as nn
from PIL import Image
from torch.autograd import Variable
import numpy as np
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import sklearn.model_selection as model_selection
from torchvision import transforms, models, datasets

print(torch.__version__)

BATCH_SIZE = 32

## transformations
####transforms.Normalize((0.4363,0.4328,0.3291),(0.2132,0.2078,0.2040))])

## download and load training dataset
from google.colab import files
files.upload()
from sklearn.model_selection import train_test_split
## X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

training_dir = '/content/gdrive/MyDrive/train.txt'
validation_dir = '/content/gdrive/MyDrive/val.txt'
testing_dir = '/content/gdrive/MyDrive/test.txt'
directories = {
    'training' : training_dir,
    'validation' : validation_dir,
    'test' : testing_dir
}

# Commented out IPython magic to ensure Python compatibility.
# % ls /content/gdrive/MyDrive/
# % pwd

from google.colab import drive
drive.mount('/content/gdrive')

transformations = {
    'training' : transforms.Compose([
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize([0.4363,0.4328,0.3291],[0.2132,0.2078,0.2040])
    ]),
    'validation' : transforms.Compose([
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize([0.4363,0.4328,0.3291],[0.2132,0.2078,0.2040])

    ]),
    'test' :transforms.Compose([
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize([0.4363,0.4328,0.3291],[0.2132,0.2078,0.2040])

    ]),
}

#Load datasets with the image folder 
image_datasets = {x:datasets.VOCSegmentation(directories[x], transform=transformations[x]) for x in ['training','validation','test']}

#Load the data into batches
## This might be incorrect dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['training', 'validation', 'test']} 
dataset_sizes = {x: len(image_datasets[x]) for x in ['training','validation', 'test']}
dataloaders = { x : torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['training', 'validation', 'test']}

               
##torchvision.datasets.MNIST(root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) → NoneeType] = None, download: bool = False) → None

from google.colab import drive
drive.mount('/content/drive')

from types import ClassMethodDescriptorType
class_names = image_datasets['train'].classes
print(class_names)
#Dowload the PASCAL VOC IMAGE IN THE JPEG SEGMENTATION

##do we have a category to name; with open('cat_to_name.json',r) as f
##print(class_names)

##to view the images trans
import torchvision
import matplotlib.pyplot as plt
def imshow(image):
  if  isinstance(image, torch.Tensor):
    image =image.nuppy().transpose((1,2,0))
  else:
        image = np.array(image).transpose((1,2,0))
        #Unnormalize 
        mean = np.array([0.485,0.456,0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = std +image + mean
        image = np.clip(image,0,1)
        plt.imshow(image)
        ##ax.axiz('off')

images, _=next(iter(dataloaders['training']))
out = torchvision.utils.make_grid(images, nrow=8)

#choosing the model
model = models.resnet50(pretrained=False)

num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 102)

for param in model.parameters():
  param.requires_grad = True

model.cuda()

##def train_model(model, criteria, optimizer, scheduler,
              ##  num_epochs = 40, device= cuda)
         ## since =time.time()
         ## best_acc = 0.0

          ##for epoch in range(1,num_epoch+1):
            ##for phrase in['train', 'valid']:
              ##if phase == train:
                ##scheduler.step()
                ##model.train()
                ##else:
                  ##model.eval()

              ##    running_loss = 0.0
                ##  running_corrects =0

                  #Iterate over data
                  ##for inputs , labels in dataloaders[phase]:
                    ##inouts = inputs.to(device)
                    ##labels = labels.to(device)

                  ##  optimizer.zero_grad()

                    ##with torch.set_grad_enabled(phase == 'train'):
                      ##outputs = model(inputs)
                      ##preds = torch.max(outputs, 1)
                      ##loss = criteria(outputs, labels)

                   ## if phase == 'train'
                     ## loss.backward()
                      ##optimizer.step()

                      ##running_loss += loss.item() * inputs.size(0)
                     ## running_corrects += torch.sum(preds == labels.data)

                      ##epoch_loss = running_loss / dataset_sizes[phase]
                      ##epoch_acc = running_corrects.double() / dataset_sizes[phase]

                  learning_rate = .0001
                  device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
                  model = MyModel()
                  model = model.to(device)
                  criterion = nn.CrossEntropyLoss()
                  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
                  for epoch in range(num_epochs):
                       train_running_loss = 0.0
                       train_acc = 0.0
 
                  model = model.train()
 
 
                 ##Make sure returning and training code match
                  for i, (images, labels) in enumerate(trainloader):
        
                    images = images.to(device)
                    labels = labels.to(device)

                    logits = model(images)
                    loss = criterion(logits, labels)

                    #(-_-) 
                    writer = SummaryWriter()
                    writer.add_scalar("Loss/train", loss, epoch)

                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    writer.flush()

                  #ALANDA is confused with this part. 
                  train_running_loss += loss.detach().item()
                  

                  ## model.eval()
                  print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \
                  %(epoch, train_running_loss / i, train_acc/i))  

#Saving the model
model.class_to_idx = image_datasets['train'].class_to_idx
model.cpu()
torch.save()
