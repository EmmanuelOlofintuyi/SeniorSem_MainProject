# -*- coding: utf-8 -*-
"""Senior Seminar Model Training

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13e_HXEcrd_BCOktMFBXz3ekfgYmVRSx3
"""

!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html

import torch
import torch.nn as nn
from PIL import Image
from torch.autograd import Variable
from torch.utils.tensorboard import SummaryWriter
from torchvision.datasets import VOCSegmentation
import numpy as np
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import sklearn.model_selection as model_selection
from torchvision import transforms, models, datasets
from torch.utils.data import DataLoader
import glob
import os

print(torch.__version__)

## transformations
####transforms.Normalize((0.4363,0.4328,0.3291),(0.2132,0.2078,0.2040))])

## download and load training dataset
from google.colab import drive
drive.mount('/content/gdrive')
## X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

#Path to JPEGImages
image_folder_path = '/content/gdrive/MyDrive/SeniorSeminar/VOCdevkit/VOC2012/JPEGImages'

#Paths to train.txt, val.txt, and trainval.txt
train_text_filenames = '/content/gdrive/MyDrive/SeniorSeminar/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt'
val_text_filenames = '/content/gdrive/MyDrive/SeniorSeminar/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt'
test_text_filenames = '/content/gdrive/MyDrive/SeniorSeminar/VOCdevkit/VOC2012/ImageSets/Segmentation/test.txt'

#Making a dictionary of paths to .txt files containting lists of jpg filenames
filename_paths = {
    'train' : train_text_filenames,
    'val' : val_text_filenames,
    'test' : test_text_filenames
}

##training_dir = '/content/gdrive/MyDrive/train.txt'
##validation_dir = '/content/gdrive/MyDrive/val.txt'
##testing_dir = '/content/gdrive/MyDrive/test.txt'
##directories = {
    ##'training' : training_dir,
    ##'validation' : validation_dir,
    ##'test' : testing_dir
##}

import glob
import os
def get_JPEGimages(image_folder_path):
    files = glob.glob(image_folder_path + '/*.jpg')
    JPEG_file_dictionary = {}
    for f in files:
      name = os.path.basename(f)
      jpg_file = open(f)
      JPEG_file_dictionary.update({name:jpg_file})
    return JPEG_file_dictionary

# Commented out IPython magic to ensure Python compatibility.
# % ls /content/gdrive/MyDrive/
# % pwd

#Creates a list of strings representing the names of files found in the .txt files
def get_list_filenames(filename_text_path):
    f = open(filename_text_path)
    list_filenames = []
    for x in f:
        fileName = x.strip('\n') + '.jpg'
        list_filenames.append(fileName)
    return list_filenames

from sklearn.model_selection import train_test_split

#Creates a dictionary of lists, each list being a list of strings that represent filenames of that imageset
def get_dictionary_of_filename_lists(filename_txt_path_dictionary):
    filename_dictionaries = {x : get_list_filenames(filename_txt_path_dictionary[x]) for x in ['train','val', 'test']}
    return filename_dictionaries

#Returns a dictionary of form {(str)imageset_name : (dict){(str)filename.jpg : (.jpg)file}}
#(eg: {'trainval' : {'01.jpg': <_io.TextIOWrapper name='/content/.../JPEGImages/01.jpg' mode='r' encoding='UTF-8'>, '02.jpg':.......}})
def build_imagesets(filename_txt_path_dictionary, image_folder_path):
    imageset_filename_dictionary = get_dictionary_of_filename_lists(filename_txt_path_dictionary)
    jpg_images_dictionary = get_JPEGimages(image_folder_path)
    imageset_dictionary = {}
    for imageset_name in imageset_filename_dictionary:
      list_of_filenames = imageset_filename_dictionary[imageset_name]
      file_dictionary = {}
      for filename in list_of_filenames:
        if filename in jpg_images_dictionary:
          file_dictionary.update({filename : jpg_images_dictionary[filename]})
      imageset_dictionary.update({imageset_name : file_dictionary})
    return imageset_dictionary

#Building imagesets
dictionary_of_imagesets = build_imagesets(filename_paths,image_folder_path)

#A printed example of the varying sizes and contents of train, val, and trainval
for x in dictionary_of_imagesets:
    print("Number of images from imageset \"" + x + "\" that matched images in JPEGImages: " + str(len(dictionary_of_imagesets[x])))
    print("Displaying contents of imageset \"" + x + "\": ")
    for y in dictionary_of_imagesets[x]:
        print(dictionary_of_imagesets[x][y])
    print('\n')
    
    
    
#Transformtions using the mean and Standard Deviation

transformations = {
    'training' : transforms.Compose([
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize([0.4363,0.4328,0.3291],[0.2132,0.2078,0.2040])
    ]),
    'validation' : transforms.Compose([
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize([0.4363,0.4328,0.3291],[0.2132,0.2078,0.2040])

    ]),
    'test' :transforms.Compose([
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize([0.4363,0.4328,0.3291],[0.2132,0.2078,0.2040])

    ]),
}

#Load datasets with the image folder 
image_datasets = {x:datasets.VOCSegmentation(directories[x], transform=transformations[x]) for x in ['training','validation','test']}

#Load the data into batches
## This might be incorrect dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['training', 'validation', 'test']} 
dataset_sizes = {x: len(image_datasets[x]) for x in ['training','validation', 'test']}
dataloaders = { x : torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['training', 'validation', 'test']}

               
##torchvision.datasets.MNIST(root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) → NoneeType] = None, download: bool = False) → None

from google.colab import drive
drive.mount('/content/drive')

from types import ClassMethodDescriptorType
class_names = image_datasets['train'].classes
print(class_names)
#Dowload the PASCAL VOC IMAGE IN THE JPEG SEGMENTATION

##do we have a category to name; with open('cat_to_name.json',r) as f
##print(class_names)

##to view the images trans
import torchvision
import matplotlib.pyplot as plt
if  isinstance(im, torch.Tensor):
    image =im.nuppy().transpose((1,2,0))
else:
        image = np.array(im).transpose((1,2,0))
        #Unnormalize 
        mean = np.array([0.485,0.456,0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = std +image + mean
        image = np.clip(image,0,1)
        ##ax.axiz('off')

images, _=next(iter(dataLoader['training']))
out = torchvision.utils.make_grid(images, nrow=8)

num_ftrs = MyModel.fc.in_features
MyModel.fc = nn.Linear(num_ftrs, 102)




for param in MyModel.parameters():
  param.requires_grad = True

Mymodel.cuda()

##def train_model(model, criteria, optimizer, scheduler,
              ##  num_epochs = 40, device= cuda)
         ## since =time.time()
         ## best_acc = 0.0

          ##for epoch in range(1,num_epoch+1):
            ##for phrase in['train', 'valid']:
              ##if phase == train:
                ##scheduler.step()
                ##model.train()
                ##else:
                  ##model.eval()

              ##    running_loss = 0.0
                ##  running_corrects =0

                  #Iterate over data
                  ##for inputs , labels in dataloaders[phase]:
                    ##inouts = inputs.to(device)
                    ##labels = labels.to(device)

                  ##  optimizer.zero_grad()

                    ##with torch.set_grad_enabled(phase == 'train'):
                      ##outputs = model(inputs)
                      ##preds = torch.max(outputs, 1)
                      ##loss = criteria(outputs, labels)

                   ## if phase == 'train'
                     ## loss.backward()
                      ##optimizer.step()

                      ##running_loss += loss.item() * inputs.size(0)
                     ## running_corrects += torch.sum(preds == labels.data)

                      ##epoch_loss = running_loss / dataset_sizes[phase]
                      ##epoch_acc = running_corrects.double() / dataset_sizes[phase]

                  def trainmodel():
  learning_rate = .0001
  num_epochs = 32
  device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
  model = MyModel()
  model = MyModel.to(device)
  criterion = nn.CrossEntropyLoss()
  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
  for epoch in range(num_epochs):
      train_running_loss = 0.0
      train_acc = 0.0
 
      model = model.train_model() 

                 ##Make sure returning and training code match
      
      for i, (images, labels) in enumerate(dataLoader):
        
                    images = images.to(device)
                    labels = labels.to(device)

                    logits = model(images)
                    loss = criterion(logits, labels)

                    #(-_-) 
                    writer = SummaryWriter()
                    writer.add_scalar("Loss/train", loss, epoch)

                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    writer.flush()
                    writer.close()

                    train_running_loss += loss.detach().item()                  

                  ## model.eval()
                    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \
                  %(epoch, train_running_loss / i, train_acc/i))  

#Saving the model
model.class_to_idx = image_datasets['train'].class_to_idx
model.cpu()
torch.save()
